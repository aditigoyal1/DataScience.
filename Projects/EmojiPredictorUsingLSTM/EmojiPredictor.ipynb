{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Predictor ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Get The Emoji Predictor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🔥'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fork_and_knife:\")\n",
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤️\n",
      "⚾\n",
      "😁\n",
      "😓\n",
      "🍴\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Processing a Custom Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test=pd.read_csv('dataset/test_emoji.csv',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "#Print the train sentences with emoji\n",
    "data=train.values\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train[0]\n",
    "Y_train=train[1]\n",
    "\n",
    "X_test=test[0]\n",
    "Y_test=test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again 😓\n",
      "I am proud of your achievements 😁\n",
      "It is the worst day in my life 😓\n",
      "Miss you so much ❤️\n",
      "food is life 🍴\n",
      "I love you mum ❤️\n",
      "Stop saying bullshit 😓\n",
      "congratulations on your acceptance 😁\n",
      "The assignment is too long  😓\n",
      "I want to go play ⚾\n",
      "she did not answer my text  😓\n",
      "Your stupidity has no limit 😓\n",
      "how many points did he score ⚾\n",
      "my algorithm performs poorly 😓\n",
      "I got approved 😁\n",
      "Stop shouting at me 😓\n",
      "Sounds like a fun plan ha ha 😁\n",
      "no one likes him 😓\n",
      "the game just finished ⚾\n",
      "I will celebrate soon 😁\n",
      "So sad you are not coming 😓\n",
      "She is my dearest love ❤️\n",
      "Good job 😁\n",
      "It was funny lol 😁\n",
      "candy is life  😁\n",
      "The chicago cubs won again ⚾\n",
      "I am hungry 🍴\n",
      "I am so excited to see you after so long 😁\n",
      "you did well on you exam 😁\n",
      "lets brunch some day 🍴\n",
      "he is so cute ❤️\n",
      "How dare you ask that 😓\n",
      "do you want to join me for dinner  🍴\n",
      "I said yes 😁\n",
      "she is attractive ❤️\n",
      "you suck 😓\n",
      "she smiles a lot 😁\n",
      "he is laughing 😁\n",
      "she takes forever to get ready  😓\n",
      "French macaroon is so tasty 🍴\n",
      "we made it 😁\n",
      "I am excited 😁\n",
      "I adore my dogs ❤️\n",
      "Congratulations 😁\n",
      "this girl was mean 😓\n",
      "you two are cute ❤️\n",
      "my code is working but the grader gave me zero 😓\n",
      "this joke is killing me haha 😁\n",
      "do you like pizza  🍴\n",
      "you got a down grade 😓\n",
      "I missed you ❤️\n",
      "I think I will end up alone 😓\n",
      "I got humiliated by my sister 😓\n",
      "you are awful 😓\n",
      "I cooked meat 🍴\n",
      "This is so funny 😁\n",
      "lets exercise ⚾\n",
      "he is the best player ⚾\n",
      "I am going to the stadium ⚾\n",
      "You are incredibly intelligent and talented 😁\n",
      "Stop shouting at me 😓\n",
      "Who is your favorite player ⚾\n",
      "I like you a lot ❤️\n",
      "i miss him ❤️\n",
      "my dog just had a few puppies ❤️\n",
      "I hate him 😓\n",
      "I want chinese food 🍴\n",
      "cookies are good 🍴\n",
      "her smile is so charming 😁\n",
      "Bravo for the announcement it got a lot of traction 😁\n",
      "she plays baseball ⚾\n",
      "he did an amazing job 😁\n",
      "The baby is adorable ❤️\n",
      "I was waiting for her for two hours  😓\n",
      "funny 😁\n",
      "I like it when people smile 😁\n",
      "I love dogs ❤️\n",
      "they are so kind and friendly ❤️\n",
      "So bad that you cannot come with us 😓\n",
      "he likes baseball ⚾\n",
      "I am so impressed by your dedication to this project 😁\n",
      "I am at the baseball game ⚾\n",
      "Bravo 😁\n",
      "What a fun moment 😁\n",
      "I want to have sushi for dinner 🍴\n",
      "I am very disappointed 😓\n",
      "he can not do anything 😓\n",
      "lol 😁\n",
      "Lets have food together 🍴\n",
      "she is so cute ❤️\n",
      "miss you my dear ❤️\n",
      "I am looking for a date ❤️\n",
      "I am frustrated 😓\n",
      "I lost my wallet 😓\n",
      "you failed the midterm 😓\n",
      "ha ha ha it was so funny 😁\n",
      "Do you want to give me a hug ❤️\n",
      "who is playing in the final ⚾\n",
      "she is happy 😁\n",
      "You are not qualified for this position 😓\n",
      "I love my dad ❤️\n",
      "this guy was such a joke 😁\n",
      "Good joke 😁\n",
      "This specialization is great 😁\n",
      "you could not solve it 😓\n",
      "I am so happy for you 😁\n",
      "Congrats on the new job 😁\n",
      "I am proud of you forever 😁\n",
      "I want to eat 🍴\n",
      "That catcher sucks  ⚾\n",
      "The first base man got the ball ⚾\n",
      "this is bad 😓\n",
      "you did not do your homework 😓\n",
      "I will have a cheese cake 🍴\n",
      "do you have a ball ⚾\n",
      "the lectures are great though  😁\n",
      "Are you down for baseball this afternoon ⚾\n",
      "what are the rules of the game ⚾\n",
      "I am always working 😓\n",
      "where is the stadium ⚾\n",
      "She is the cutest person I have ever seen ❤️\n",
      "vegetables are healthy 🍴\n",
      "he is handsome ❤️\n",
      "too bad that you were not here 😓\n",
      "you are a loser 😓\n",
      "I love indian food 🍴\n",
      "Who is down for a restaurant 🍴\n",
      "he had to make a home run ⚾\n",
      "I am ordering food 🍴\n",
      "What is wrong with you 😓\n",
      "I love you ❤️\n",
      "great job 😁\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    print(X_train[i],end=\" \")\n",
    "    print(emoji.emojize(emoji_dictionary[str(Y_train[i])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 Converting Sentences into Embedding ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('dataset/glove.6B.50d.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove file contains words and its corresponding 50d vector which contains it's representation\n",
    "embedding_index={}\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float')\n",
    "    embedding_index[word]=coefs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.089859,  0.5691  , -0.91323 ,  0.34064 ,  0.7763  ,  1.3755  ,\n",
       "       -0.6681  , -0.322   , -0.061527,  0.81761 ,  0.1773  , -0.24408 ,\n",
       "        1.1812  ,  0.65863 ,  0.77332 ,  0.40388 , -0.31354 ,  0.35177 ,\n",
       "       -0.10074 , -1.6919  ,  0.70704 , -0.14594 ,  0.93264 ,  0.4056  ,\n",
       "       -0.49499 ,  0.16782 , -1.5197  ,  1.0247  ,  1.282   , -0.33623 ,\n",
       "        1.2153  , -0.065825, -1.2306  ,  1.4039  , -0.16776 , -0.40948 ,\n",
       "       -0.92448 ,  0.99141 ,  1.5194  , -0.54659 ,  0.93013 ,  0.17938 ,\n",
       "       -0.17086 , -0.42733 ,  0.75439 ,  1.4537  , -0.098187, -0.59428 ,\n",
       "       -0.19965 , -0.49592 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.close()\n",
    "embedding_index['chocolate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4 Converting sentences into vectors(Embedding layer Output) ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in glove vector each is represented by 50 size array so emb_dim=50\n",
    "#max_len =10 means in each sentences we want starting 10 words only\n",
    "\n",
    "def embedding_output(X):\n",
    "    max_len=10\n",
    "    emb_dim=50\n",
    "    embedding_out=np.zeros((X.shape[0],max_len,emb_dim))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        #here first we need to split each sentences\n",
    "        #print(X[i])\n",
    "        X[i]=X[i].split()\n",
    "        for j in range(min(len(X[i]),10)):\n",
    "            #iterate to every word in the current(i) sentence\n",
    "            \n",
    "            try:\n",
    "                embedding_out[i][j]=embedding_index[X[i][j].lower()]\n",
    "            except:\n",
    "                embedding_out[i][j]=np.zeros((50,))\n",
    "    return embedding_out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_train=embedding_output(X_train)\n",
    "embedding_matrix_test=embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'proud', 'of', 'your', 'achievements']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape)\n",
    "print(embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never', 'talk', 'to', 'me', 'again']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(Y_train,num_classes=5)\n",
    "Y_test=to_categorical(Y_test,num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5 Define the RNN/LSTM Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Stacked LSTM\n",
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/150\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.6017 - acc: 0.2381 - val_loss: 1.6127 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.22222, saving model to best_model.h5\n",
      "Epoch 2/150\n",
      "105/105 [==============================] - 0s 541us/step - loss: 1.5793 - acc: 0.2762 - val_loss: 1.6132 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.22222\n",
      "Epoch 3/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 1.5477 - acc: 0.2667 - val_loss: 1.6212 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.22222\n",
      "Epoch 4/150\n",
      "105/105 [==============================] - 0s 636us/step - loss: 1.5330 - acc: 0.3143 - val_loss: 1.6339 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.22222\n",
      "Epoch 5/150\n",
      "105/105 [==============================] - 0s 598us/step - loss: 1.5034 - acc: 0.3143 - val_loss: 1.6471 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.22222\n",
      "Epoch 6/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 1.4992 - acc: 0.3524 - val_loss: 1.6613 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.22222\n",
      "Epoch 7/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 1.4700 - acc: 0.4000 - val_loss: 1.6694 - val_acc: 0.2593\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.22222 to 0.25926, saving model to best_model.h5\n",
      "Epoch 8/150\n",
      "105/105 [==============================] - 0s 579us/step - loss: 1.4658 - acc: 0.4000 - val_loss: 1.6740 - val_acc: 0.2593\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.25926\n",
      "Epoch 9/150\n",
      "105/105 [==============================] - 0s 579us/step - loss: 1.4224 - acc: 0.4571 - val_loss: 1.6763 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.25926\n",
      "Epoch 10/150\n",
      "105/105 [==============================] - 0s 693us/step - loss: 1.4078 - acc: 0.3905 - val_loss: 1.6646 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.25926\n",
      "Epoch 11/150\n",
      "105/105 [==============================] - 0s 674us/step - loss: 1.3924 - acc: 0.4286 - val_loss: 1.6425 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.25926\n",
      "Epoch 12/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 1.3553 - acc: 0.4381 - val_loss: 1.6120 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.25926\n",
      "Epoch 13/150\n",
      "105/105 [==============================] - 0s 646us/step - loss: 1.3026 - acc: 0.4952 - val_loss: 1.5786 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.25926\n",
      "Epoch 14/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 1.2642 - acc: 0.5048 - val_loss: 1.5492 - val_acc: 0.2593\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.25926\n",
      "Epoch 15/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 1.2392 - acc: 0.5333 - val_loss: 1.5068 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.25926 to 0.37037, saving model to best_model.h5\n",
      "Epoch 16/150\n",
      "105/105 [==============================] - 0s 598us/step - loss: 1.1862 - acc: 0.5810 - val_loss: 1.4540 - val_acc: 0.4074\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.37037 to 0.40741, saving model to best_model.h5\n",
      "Epoch 17/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 1.0890 - acc: 0.6381 - val_loss: 1.4033 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.40741\n",
      "Epoch 18/150\n",
      "105/105 [==============================] - 0s 646us/step - loss: 1.0310 - acc: 0.6571 - val_loss: 1.3726 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.40741\n",
      "Epoch 19/150\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.9864 - acc: 0.6476 - val_loss: 1.3627 - val_acc: 0.4074\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.40741\n",
      "Epoch 20/150\n",
      "105/105 [==============================] - 0s 703us/step - loss: 0.9661 - acc: 0.6476 - val_loss: 1.2865 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.40741 to 0.51852, saving model to best_model.h5\n",
      "Epoch 21/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.9171 - acc: 0.6476 - val_loss: 1.1803 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.51852\n",
      "Epoch 22/150\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.8151 - acc: 0.7048 - val_loss: 1.1161 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.51852 to 0.59259, saving model to best_model.h5\n",
      "Epoch 23/150\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.7114 - acc: 0.7524 - val_loss: 1.1228 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.59259\n",
      "Epoch 24/150\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.6774 - acc: 0.7905 - val_loss: 1.2681 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.59259\n",
      "Epoch 25/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.7223 - acc: 0.7333 - val_loss: 1.2481 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.59259\n",
      "Epoch 26/150\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.5918 - acc: 0.7905 - val_loss: 1.1110 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.59259\n",
      "Epoch 27/150\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.5744 - acc: 0.8000 - val_loss: 0.9989 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.59259 to 0.66667, saving model to best_model.h5\n",
      "Epoch 28/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.5359 - acc: 0.8381 - val_loss: 1.0613 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.66667\n",
      "Epoch 29/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.4866 - acc: 0.8667 - val_loss: 1.1666 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.66667\n",
      "Epoch 30/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.4443 - acc: 0.8667 - val_loss: 1.1866 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.66667\n",
      "Epoch 31/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.3816 - acc: 0.9048 - val_loss: 1.0738 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.66667 to 0.70370, saving model to best_model.h5\n",
      "Epoch 32/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.3763 - acc: 0.9333 - val_loss: 1.1260 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.70370\n",
      "Epoch 33/150\n",
      "105/105 [==============================] - 0s 712us/step - loss: 0.3567 - acc: 0.8952 - val_loss: 1.1775 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.70370\n",
      "Epoch 34/150\n",
      "105/105 [==============================] - 0s 684us/step - loss: 0.2723 - acc: 0.9429 - val_loss: 1.2852 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.70370\n",
      "Epoch 35/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.3213 - acc: 0.8952 - val_loss: 1.0911 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.70370\n",
      "Epoch 36/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.2736 - acc: 0.9333 - val_loss: 0.9592 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.70370\n",
      "Epoch 37/150\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.2363 - acc: 0.9333 - val_loss: 1.0214 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.70370\n",
      "Epoch 38/150\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.2288 - acc: 0.9524 - val_loss: 1.1178 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.70370\n",
      "Epoch 39/150\n",
      "105/105 [==============================] - 0s 712us/step - loss: 0.1841 - acc: 0.9429 - val_loss: 1.2405 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.70370\n",
      "Epoch 40/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.1709 - acc: 0.9619 - val_loss: 1.2563 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.70370\n",
      "Epoch 41/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.1157 - acc: 0.9619 - val_loss: 1.2422 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.70370\n",
      "Epoch 42/150\n",
      "105/105 [==============================] - 0s 912us/step - loss: 0.1680 - acc: 0.9429 - val_loss: 1.3851 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.70370\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 807us/step - loss: 0.1725 - acc: 0.9429 - val_loss: 1.3602 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.70370\n",
      "Epoch 44/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.1326 - acc: 0.9619 - val_loss: 1.3414 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.70370\n",
      "Epoch 45/150\n",
      "105/105 [==============================] - 0s 741us/step - loss: 0.1948 - acc: 0.9238 - val_loss: 1.3114 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.70370\n",
      "Epoch 46/150\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9714 - val_loss: 1.3011 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.70370\n",
      "Epoch 47/150\n",
      "105/105 [==============================] - 0s 798us/step - loss: 0.1202 - acc: 0.9810 - val_loss: 1.2338 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.70370 to 0.77778, saving model to best_model.h5\n",
      "Epoch 48/150\n",
      "105/105 [==============================] - 0s 722us/step - loss: 0.0964 - acc: 0.9810 - val_loss: 1.3564 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.77778\n",
      "Epoch 49/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.1246 - acc: 0.9619 - val_loss: 1.3367 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.77778\n",
      "Epoch 50/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.1116 - acc: 0.9714 - val_loss: 1.1111 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.77778\n",
      "Epoch 51/150\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.1242 - acc: 0.9524 - val_loss: 1.2883 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.77778\n",
      "Epoch 52/150\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.1362 - acc: 0.9714 - val_loss: 1.4631 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.77778\n",
      "Epoch 53/150\n",
      "105/105 [==============================] - 0s 902us/step - loss: 0.1215 - acc: 0.9619 - val_loss: 1.4440 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.77778\n",
      "Epoch 54/150\n",
      "105/105 [==============================] - 0s 769us/step - loss: 0.0544 - acc: 0.9905 - val_loss: 1.7302 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.77778\n",
      "Epoch 55/150\n",
      "105/105 [==============================] - 0s 912us/step - loss: 0.1566 - acc: 0.9810 - val_loss: 1.6786 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.77778\n",
      "Epoch 56/150\n",
      "105/105 [==============================] - 0s 855us/step - loss: 0.1248 - acc: 0.9524 - val_loss: 1.5833 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.77778\n",
      "Epoch 57/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.1080 - acc: 0.9619 - val_loss: 1.5943 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.77778\n",
      "Epoch 58/150\n",
      "105/105 [==============================] - 0s 731us/step - loss: 0.0934 - acc: 0.9619 - val_loss: 1.6478 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.77778\n",
      "Epoch 59/150\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.0962 - acc: 0.9810 - val_loss: 1.5713 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.77778\n",
      "Epoch 60/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0622 - acc: 0.9905 - val_loss: 1.5087 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.77778\n",
      "Epoch 61/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0843 - acc: 0.9714 - val_loss: 1.4708 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.77778\n",
      "Epoch 62/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0944 - acc: 0.9714 - val_loss: 1.5702 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.77778\n",
      "Epoch 63/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.1367 - acc: 0.9714 - val_loss: 1.5782 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.77778\n",
      "Epoch 64/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0500 - acc: 0.9810 - val_loss: 1.7079 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.77778\n",
      "Epoch 65/150\n",
      "105/105 [==============================] - 0s 760us/step - loss: 0.0540 - acc: 0.9905 - val_loss: 1.6865 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.77778\n",
      "Epoch 66/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0682 - acc: 0.9905 - val_loss: 1.4169 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.77778\n",
      "Epoch 67/150\n",
      "105/105 [==============================] - 0s 874us/step - loss: 0.0317 - acc: 1.0000 - val_loss: 1.2812 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.77778\n",
      "Epoch 68/150\n",
      "105/105 [==============================] - 0s 855us/step - loss: 0.0574 - acc: 0.9905 - val_loss: 1.3541 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.77778\n",
      "Epoch 69/150\n",
      "105/105 [==============================] - 0s 798us/step - loss: 0.0519 - acc: 0.9905 - val_loss: 1.5419 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.77778\n",
      "Epoch 70/150\n",
      "105/105 [==============================] - 0s 769us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 1.6039 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.77778\n",
      "Epoch 71/150\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.5848 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.77778\n",
      "Epoch 72/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0401 - acc: 0.9905 - val_loss: 1.4522 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.77778\n",
      "Epoch 73/150\n",
      "105/105 [==============================] - 0s 855us/step - loss: 0.0323 - acc: 0.9905 - val_loss: 1.3888 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.77778\n",
      "Epoch 74/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.0372 - acc: 0.9905 - val_loss: 1.4497 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.77778\n",
      "Epoch 75/150\n",
      "105/105 [==============================] - 0s 864us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 1.6579 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.77778\n",
      "Epoch 76/150\n",
      "105/105 [==============================] - 0s 874us/step - loss: 0.0574 - acc: 0.9905 - val_loss: 1.7308 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.77778\n",
      "Epoch 77/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0378 - acc: 0.9905 - val_loss: 1.7051 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.77778\n",
      "Epoch 78/150\n",
      "105/105 [==============================] - 0s 883us/step - loss: 0.0281 - acc: 0.9905 - val_loss: 1.5967 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.77778\n",
      "Epoch 79/150\n",
      "105/105 [==============================] - 0s 855us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 1.6098 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.77778\n",
      "Epoch 80/150\n",
      "105/105 [==============================] - 0s 940us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.6336 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.77778\n",
      "Epoch 81/150\n",
      "105/105 [==============================] - 0s 864us/step - loss: 0.0224 - acc: 0.9905 - val_loss: 1.6572 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.77778\n",
      "Epoch 82/150\n",
      "105/105 [==============================] - 0s 836us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 1.7060 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.77778\n",
      "Epoch 83/150\n",
      "105/105 [==============================] - 0s 779us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 1.7472 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.77778\n",
      "Epoch 84/150\n",
      "105/105 [==============================] - 0s 722us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.7875 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.77778\n",
      "Epoch 85/150\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.8355 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.77778\n",
      "Epoch 86/150\n",
      "105/105 [==============================] - 0s 912us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.8686 - val_acc: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: val_acc did not improve from 0.77778\n",
      "Epoch 87/150\n",
      "105/105 [==============================] - 0s 836us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.8585 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.77778\n",
      "Epoch 88/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.8571 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.77778\n",
      "Epoch 89/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.8256 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.77778\n",
      "Epoch 90/150\n",
      "105/105 [==============================] - 0s 817us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.8038 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.77778\n",
      "Epoch 91/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.7880 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.77778\n",
      "Epoch 92/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.7860 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.77778\n",
      "Epoch 93/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.8101 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.77778\n",
      "Epoch 94/150\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0093 - acc: 1.000 - 0s 836us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.8293 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.77778\n",
      "Epoch 95/150\n",
      "105/105 [==============================] - 0s 817us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.8352 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.77778\n",
      "Epoch 96/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 1.8283 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.77778\n",
      "Epoch 97/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.8137 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.77778\n",
      "Epoch 98/150\n",
      "105/105 [==============================] - 0s 798us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.8073 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.77778\n",
      "Epoch 99/150\n",
      "105/105 [==============================] - 0s 836us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.8020 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.77778\n",
      "Epoch 100/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.7952 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.77778\n",
      "Epoch 101/150\n",
      "105/105 [==============================] - 0s 836us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 1.8027 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.77778\n",
      "Epoch 102/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.8092 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.77778\n",
      "Epoch 103/150\n",
      "105/105 [==============================] - 0s 798us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.8117 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.77778\n",
      "Epoch 104/150\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.8080 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.77778\n",
      "Epoch 105/150\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.7947 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.77778\n",
      "Epoch 106/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.7830 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.77778\n",
      "Epoch 107/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.7738 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.77778\n",
      "Epoch 108/150\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.7671 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.77778\n",
      "Epoch 109/150\n",
      "105/105 [==============================] - 0s 798us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.7617 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.77778\n",
      "Epoch 110/150\n",
      "105/105 [==============================] - 0s 931us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 1.7455 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.77778\n",
      "Epoch 111/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.7310 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.77778\n",
      "Epoch 112/150\n",
      "105/105 [==============================] - 0s 874us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.7266 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.77778\n",
      "Epoch 113/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.7337 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.77778\n",
      "Epoch 114/150\n",
      "105/105 [==============================] - 0s 855us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 1.7481 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.77778\n",
      "Epoch 115/150\n",
      "105/105 [==============================] - 0s 788us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.7680 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.77778\n",
      "Epoch 116/150\n",
      "105/105 [==============================] - 0s 684us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.7915 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.77778\n",
      "Epoch 117/150\n",
      "105/105 [==============================] - 0s 931us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.8225 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.77778\n",
      "Epoch 118/150\n",
      "105/105 [==============================] - 0s 741us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.8657 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.77778\n",
      "Epoch 119/150\n",
      "105/105 [==============================] - 0s 722us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.8849 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.77778\n",
      "Epoch 120/150\n",
      "105/105 [==============================] - 0s 741us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 1.8839 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.77778\n",
      "Epoch 121/150\n",
      "105/105 [==============================] - 0s 712us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.8789 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.77778\n",
      "Epoch 122/150\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.8839 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.77778\n",
      "Epoch 123/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.9001 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.77778\n",
      "Epoch 124/150\n",
      "105/105 [==============================] - 0s 646us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.9168 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.77778\n",
      "Epoch 125/150\n",
      "105/105 [==============================] - 0s 874us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.9314 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.77778\n",
      "Epoch 126/150\n",
      "105/105 [==============================] - 0s 940us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.9487 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.77778\n",
      "Epoch 127/150\n",
      "105/105 [==============================] - 0s 845us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.9841 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.77778\n",
      "Epoch 128/150\n",
      "105/105 [==============================] - 0s 864us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.0285 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.77778\n",
      "Epoch 129/150\n",
      "105/105 [==============================] - 0s 788us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.0623 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.77778\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 703us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.0489 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.77778\n",
      "Epoch 131/150\n",
      "105/105 [==============================] - 0s 674us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 2.1734 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.77778\n",
      "Epoch 132/150\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.2339 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.77778\n",
      "Epoch 133/150\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.2404 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.77778\n",
      "Epoch 134/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.2379 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.77778\n",
      "Epoch 135/150\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.2178 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.77778\n",
      "Epoch 136/150\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.1668 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.77778\n",
      "Epoch 137/150\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1135 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.77778\n",
      "Epoch 138/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.0613 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.77778\n",
      "Epoch 139/150\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.0123 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.77778\n",
      "Epoch 140/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.9973 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.77778\n",
      "Epoch 141/150\n",
      "105/105 [==============================] - 0s 788us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.0050 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.77778\n",
      "Epoch 142/150\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.0155 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.77778\n",
      "Epoch 143/150\n",
      "105/105 [==============================] - 0s 864us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.1622 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.77778\n",
      "Epoch 144/150\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.2782 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.77778\n",
      "Epoch 145/150\n",
      "105/105 [==============================] - 0s 731us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3480 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.77778\n",
      "Epoch 146/150\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.3069 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.77778\n",
      "Epoch 147/150\n",
      "105/105 [==============================] - 0s 684us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.0612 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.77778\n",
      "Epoch 148/150\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.1963 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.77778\n",
      "Epoch 149/150\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0281 - acc: 0.9905 - val_loss: 1.9744 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.77778\n",
      "Epoch 150/150\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.2330 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.77778\n"
     ]
    }
   ],
   "source": [
    "checkpoint=ModelCheckpoint('best_model.h5',monitor='val_acc',verbose=True,save_best_only=True,mode=\"auto\")\n",
    "#earlystop=EarlyStopping(monitor=\"val_acc\",patience=10)\n",
    "hist=model.fit(embedding_matrix_train,Y_train,epochs=150,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmojiPredictor.ipynb\n",
      "README.md\n",
      "best_model.h5\n",
      "dataset\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 267us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.408058864729745, 0.6428571343421936]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embedding_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 10, 50)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "TRUE EMOJI:🍴\n",
      "Predicted🍴\n",
      "\n",
      "he did not answer\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "he got a raise\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "she got me a present\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "ha ha ha it was so funny\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "he is a good friend\n",
      "TRUE EMOJI:❤️\n",
      "Predicted😁\n",
      "\n",
      "I am upset\n",
      "TRUE EMOJI:❤️\n",
      "Predicted😓\n",
      "\n",
      "We had such a lovely dinner tonight\n",
      "TRUE EMOJI:❤️\n",
      "Predicted😁\n",
      "\n",
      "where is the food\n",
      "TRUE EMOJI:🍴\n",
      "Predicted🍴\n",
      "\n",
      "Stop making this joke ha ha ha\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "where is the ball\n",
      "TRUE EMOJI:⚾\n",
      "Predicted⚾\n",
      "\n",
      "work is hard\n",
      "TRUE EMOJI:😓\n",
      "Predicted😁\n",
      "\n",
      "This girl is messing with me\n",
      "TRUE EMOJI:😓\n",
      "Predicted❤️\n",
      "\n",
      "are you serious ha ha\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "Let us go play baseball\n",
      "TRUE EMOJI:⚾\n",
      "Predicted⚾\n",
      "\n",
      "This stupid grader is not working\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "work is horrible\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "Congratulation for having a baby\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "stop messing around\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "any suggestions for dinner\n",
      "TRUE EMOJI:🍴\n",
      "Predicted😁\n",
      "\n",
      "I love taking breaks\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "you brighten my day\n",
      "TRUE EMOJI:😁\n",
      "Predicted❤️\n",
      "\n",
      "I boiled rice\n",
      "TRUE EMOJI:🍴\n",
      "Predicted🍴\n",
      "\n",
      "she is a bully\n",
      "TRUE EMOJI:😓\n",
      "Predicted❤️\n",
      "\n",
      "Why are you feeling bad\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "I am upset\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "I worked during my birthday\n",
      "TRUE EMOJI:😓\n",
      "Predicted😁\n",
      "\n",
      "My grandmother is the love of my life\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "enjoy your break\n",
      "TRUE EMOJI:😁\n",
      "Predicted⚾\n",
      "\n",
      "valentine day is near\n",
      "TRUE EMOJI:❤️\n",
      "Predicted😁\n",
      "\n",
      "I miss you so much\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "throw the ball\n",
      "TRUE EMOJI:⚾\n",
      "Predicted⚾\n",
      "\n",
      "My life is so boring\n",
      "TRUE EMOJI:😓\n",
      "Predicted❤️\n",
      "\n",
      "she said yes\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "will you be my valentine\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "he can pitch really well\n",
      "TRUE EMOJI:⚾\n",
      "Predicted⚾\n",
      "\n",
      "dance with me\n",
      "TRUE EMOJI:😁\n",
      "Predicted⚾\n",
      "\n",
      "I am starving\n",
      "TRUE EMOJI:🍴\n",
      "Predicted😓\n",
      "\n",
      "See you at the restaurant\n",
      "TRUE EMOJI:🍴\n",
      "Predicted🍴\n",
      "\n",
      "I like to laugh\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "I will go dance\n",
      "TRUE EMOJI:😁\n",
      "Predicted⚾\n",
      "\n",
      "I like your jacket\n",
      "TRUE EMOJI:😁\n",
      "Predicted❤️\n",
      "\n",
      "i miss her\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "what is your favorite baseball game\n",
      "TRUE EMOJI:⚾\n",
      "Predicted⚾\n",
      "\n",
      "Good job\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "I love to the stars and back\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "What you did was awesome\n",
      "TRUE EMOJI:😁\n",
      "Predicted😓\n",
      "\n",
      "ha ha ha lol\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "I want to joke\n",
      "TRUE EMOJI:😁\n",
      "Predicted😓\n",
      "\n",
      "go away\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "yesterday we lost again\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "family is all I have\n",
      "TRUE EMOJI:❤️\n",
      "Predicted❤️\n",
      "\n",
      "you are failing this exercise\n",
      "TRUE EMOJI:😓\n",
      "Predicted😓\n",
      "\n",
      "Good joke\n",
      "TRUE EMOJI:😁\n",
      "Predicted😁\n",
      "\n",
      "You totally deserve this prize\n",
      "TRUE EMOJI:😁\n",
      "Predicted😓\n",
      "\n",
      "I did not have breakfast\n",
      "TRUE EMOJI:😓\n",
      "Predicted❤️\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    print(\" \".join(X_test[i]))\n",
    "    print(\"TRUE EMOJI:\"+emoji.emojize(emoji_dictionary[str(np.argmax(Y_test[i]))]))\n",
    "    print(\"Predicted\"+emoji.emojize(emoji_dictionary[str(pred[i])]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
