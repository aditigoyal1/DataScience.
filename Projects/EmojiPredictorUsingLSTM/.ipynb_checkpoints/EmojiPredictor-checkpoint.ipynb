{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Predictor ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Get The Emoji Predictor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-0.5.4-cp37-none-any.whl size=42181 sha256=f4f648aae896f8e21fa487eb52944c9872757a20e6b4f47026a94369410cc269\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\pip\\Cache\\wheels\\2a\\a9\\0a\\4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🔥'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fork_and_knife:\")\n",
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤️\n",
      "⚾\n",
      "😁\n",
      "😓\n",
      "🍴\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Processing a Custom Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test=pd.read_csv('dataset/test_emoji.csv',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "#Print the train sentences with emoji\n",
    "data=train.values\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train[0]\n",
    "Y_train=train[1]\n",
    "\n",
    "X_test=test[0]\n",
    "Y_test=test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] 😓\n",
      "I am proud of your achievements 😁\n",
      "It is the worst day in my life 😓\n",
      "Miss you so much ❤️\n",
      "food is life 🍴\n",
      "I love you mum ❤️\n",
      "Stop saying bullshit 😓\n",
      "congratulations on your acceptance 😁\n",
      "The assignment is too long  😓\n",
      "I want to go play ⚾\n",
      "she did not answer my text  😓\n",
      "Your stupidity has no limit 😓\n",
      "how many points did he score ⚾\n",
      "my algorithm performs poorly 😓\n",
      "I got approved 😁\n",
      "Stop shouting at me 😓\n",
      "Sounds like a fun plan ha ha 😁\n",
      "no one likes him 😓\n",
      "the game just finished ⚾\n",
      "I will celebrate soon 😁\n",
      "So sad you are not coming 😓\n",
      "She is my dearest love ❤️\n",
      "Good job 😁\n",
      "It was funny lol 😁\n",
      "candy is life  😁\n",
      "The chicago cubs won again ⚾\n",
      "I am hungry 🍴\n",
      "I am so excited to see you after so long 😁\n",
      "you did well on you exam 😁\n",
      "lets brunch some day 🍴\n",
      "he is so cute ❤️\n",
      "How dare you ask that 😓\n",
      "do you want to join me for dinner  🍴\n",
      "I said yes 😁\n",
      "she is attractive ❤️\n",
      "you suck 😓\n",
      "she smiles a lot 😁\n",
      "he is laughing 😁\n",
      "she takes forever to get ready  😓\n",
      "French macaroon is so tasty 🍴\n",
      "we made it 😁\n",
      "I am excited 😁\n",
      "I adore my dogs ❤️\n",
      "Congratulations 😁\n",
      "this girl was mean 😓\n",
      "you two are cute ❤️\n",
      "my code is working but the grader gave me zero 😓\n",
      "this joke is killing me haha 😁\n",
      "do you like pizza  🍴\n",
      "you got a down grade 😓\n",
      "I missed you ❤️\n",
      "I think I will end up alone 😓\n",
      "I got humiliated by my sister 😓\n",
      "you are awful 😓\n",
      "I cooked meat 🍴\n",
      "This is so funny 😁\n",
      "lets exercise ⚾\n",
      "he is the best player ⚾\n",
      "I am going to the stadium ⚾\n",
      "You are incredibly intelligent and talented 😁\n",
      "Stop shouting at me 😓\n",
      "Who is your favorite player ⚾\n",
      "I like you a lot ❤️\n",
      "i miss him ❤️\n",
      "my dog just had a few puppies ❤️\n",
      "I hate him 😓\n",
      "I want chinese food 🍴\n",
      "cookies are good 🍴\n",
      "her smile is so charming 😁\n",
      "Bravo for the announcement it got a lot of traction 😁\n",
      "she plays baseball ⚾\n",
      "he did an amazing job 😁\n",
      "The baby is adorable ❤️\n",
      "I was waiting for her for two hours  😓\n",
      "funny 😁\n",
      "I like it when people smile 😁\n",
      "I love dogs ❤️\n",
      "they are so kind and friendly ❤️\n",
      "So bad that you cannot come with us 😓\n",
      "he likes baseball ⚾\n",
      "I am so impressed by your dedication to this project 😁\n",
      "I am at the baseball game ⚾\n",
      "Bravo 😁\n",
      "What a fun moment 😁\n",
      "I want to have sushi for dinner 🍴\n",
      "I am very disappointed 😓\n",
      "he can not do anything 😓\n",
      "lol 😁\n",
      "Lets have food together 🍴\n",
      "she is so cute ❤️\n",
      "miss you my dear ❤️\n",
      "I am looking for a date ❤️\n",
      "I am frustrated 😓\n",
      "I lost my wallet 😓\n",
      "you failed the midterm 😓\n",
      "ha ha ha it was so funny 😁\n",
      "Do you want to give me a hug ❤️\n",
      "who is playing in the final ⚾\n",
      "she is happy 😁\n",
      "You are not qualified for this position 😓\n",
      "I love my dad ❤️\n",
      "this guy was such a joke 😁\n",
      "Good joke 😁\n",
      "This specialization is great 😁\n",
      "you could not solve it 😓\n",
      "I am so happy for you 😁\n",
      "Congrats on the new job 😁\n",
      "I am proud of you forever 😁\n",
      "I want to eat 🍴\n",
      "That catcher sucks  ⚾\n",
      "The first base man got the ball ⚾\n",
      "this is bad 😓\n",
      "you did not do your homework 😓\n",
      "I will have a cheese cake 🍴\n",
      "do you have a ball ⚾\n",
      "the lectures are great though  😁\n",
      "Are you down for baseball this afternoon ⚾\n",
      "what are the rules of the game ⚾\n",
      "I am always working 😓\n",
      "where is the stadium ⚾\n",
      "She is the cutest person I have ever seen ❤️\n",
      "vegetables are healthy 🍴\n",
      "he is handsome ❤️\n",
      "too bad that you were not here 😓\n",
      "you are a loser 😓\n",
      "I love indian food 🍴\n",
      "Who is down for a restaurant 🍴\n",
      "he had to make a home run ⚾\n",
      "I am ordering food 🍴\n",
      "What is wrong with you 😓\n",
      "I love you ❤️\n",
      "great job 😁\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    print(X_train[i],end=\" \")\n",
    "    print(emoji.emojize(emoji_dictionary[str(Y_train[i])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 Converting Sentences into Embedding ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('dataset/glove.6B.50d.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove file contains words and its corresponding 50d vector which contains it's representation\n",
    "embedding_index={}\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float')\n",
    "    embedding_index[word]=coefs\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.089859,  0.5691  , -0.91323 ,  0.34064 ,  0.7763  ,  1.3755  ,\n",
       "       -0.6681  , -0.322   , -0.061527,  0.81761 ,  0.1773  , -0.24408 ,\n",
       "        1.1812  ,  0.65863 ,  0.77332 ,  0.40388 , -0.31354 ,  0.35177 ,\n",
       "       -0.10074 , -1.6919  ,  0.70704 , -0.14594 ,  0.93264 ,  0.4056  ,\n",
       "       -0.49499 ,  0.16782 , -1.5197  ,  1.0247  ,  1.282   , -0.33623 ,\n",
       "        1.2153  , -0.065825, -1.2306  ,  1.4039  , -0.16776 , -0.40948 ,\n",
       "       -0.92448 ,  0.99141 ,  1.5194  , -0.54659 ,  0.93013 ,  0.17938 ,\n",
       "       -0.17086 , -0.42733 ,  0.75439 ,  1.4537  , -0.098187, -0.59428 ,\n",
       "       -0.19965 , -0.49592 ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['chocolate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4 Converting sentences into vectors(Embedding layer Output) ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in glove vector each is represented by 50 size array so emb_dim=50\n",
    "#max_len =10 means in each sentences we want starting 10 words only\n",
    "\n",
    "def embedding_output(X):\n",
    "    max_len=10\n",
    "    emb_dim=50\n",
    "    embedding_out=np.zeros((X.shape[0],max_len,emb_dim))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        #here first we need to split each sentences\n",
    "        #print(X[i])\n",
    "        #X[i]=X[i].split()\n",
    "        for j in range(min(len(X[i]),10)):\n",
    "            #iterate to every word in the current(i) sentence\n",
    "            \n",
    "            try:\n",
    "                embedding_out[i][j]=embedding_index[X[i][j].lower()]\n",
    "            except:\n",
    "                embedding_out[i][j]=np.zeros((50,))\n",
    "    return embedding_out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train=embedding_output(X_train)\n",
    "embedding_matrix_test=embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am proud of your achievements\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape)\n",
    "print(embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never', 'talk', 'to', 'me', 'again']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(Y_train,num_classes=5)\n",
    "Y_test=to_categorical(Y_test,num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5 Define the RNN/LSTM Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 1.6537 - acc: 0.2119 - val_loss: 1.6968 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.07143, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.6294 - acc: 0.1695 - val_loss: 1.7198 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.07143\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 0s 465us/step - loss: 1.5475 - acc: 0.3136 - val_loss: 1.7411 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.07143\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 0s 392us/step - loss: 1.5468 - acc: 0.2881 - val_loss: 1.7607 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.07143 to 0.14286, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 0s 503us/step - loss: 1.5573 - acc: 0.2881 - val_loss: 1.7671 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.14286\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 0s 516us/step - loss: 1.5289 - acc: 0.2797 - val_loss: 1.7672 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.14286\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 0s 447us/step - loss: 1.4948 - acc: 0.3390 - val_loss: 1.7674 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.14286\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 0s 439us/step - loss: 1.5204 - acc: 0.3305 - val_loss: 1.7618 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.14286\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 0s 482us/step - loss: 1.5034 - acc: 0.3729 - val_loss: 1.7590 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.14286\n"
     ]
    }
   ],
   "source": [
    "checkpoint=ModelCheckpoint('best_model.h5',monitor='val_acc',verbose=True,save_best_only=True)\n",
    "earlystop=EarlyStopping(monitor=\"val_acc\",patience=5)\n",
    "hist=model.fit(embedding_matrix_train,Y_train,epochs=100,batch_size=64,shuffle=True,validation_split=0.1,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmojiPredictor.ipynb\n",
      "README.md\n",
      "best_model.h5\n",
      "dataset\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_4_input to have 3 dimensions, but got array with shape (56, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-e53a54440405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_4_input to have 3 dimensions, but got array with shape (56, 1)"
     ]
    }
   ],
   "source": [
    "model.evaluate(embedding_matrix_test,Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
